{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a26c3823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from datetime import time, datetime, timedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b99e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __to_hr_mean(x):\n",
    "    try:\n",
    "        return np.mean(1000/np.array(ast.literal_eval(x))*60)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def nni_to_hr_means(df):\n",
    "    df['hr_means'] = df['nni'].apply(lambda x: __to_hr_mean(x))\n",
    "    return df\n",
    "\n",
    "def load_csv_file(csv_file):\n",
    "    df = pd.read_csv(csv_file)    \n",
    "    # convert to datetime\n",
    "    df['from_time'] = pd.to_datetime(df['from_time'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "    df['to_time'] = pd.to_datetime(df['to_time'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "    return df\n",
    "\n",
    "def convert_to_awd(df, column, awd_file, data_meta):\n",
    "    df[column].to_csv(awd_file, index=False)\n",
    "    with open(awd_file, \"r\") as f:\n",
    "        contents = f.readlines()\n",
    "\n",
    "    for i, v in enumerate(data_meta.values()):\n",
    "        contents.insert(i, v+'\\n')\n",
    "\n",
    "    with open(awd_file, \"w\") as f:\n",
    "        contents = \"\".join(contents)\n",
    "        f.write(contents)\n",
    "\n",
    "def generate_awd_from_calculated_nni_df(csv_file, channels, duration, label=''):\n",
    "    # load dataframe\n",
    "    df = load_csv_file(csv_file)\n",
    "    \n",
    "    data_log = {}\n",
    "    \n",
    "    # loop for each channel\n",
    "    for channel in channels:\n",
    "        data_meta = {\n",
    "            'name' : f'{label}-Channel-{channel}',\n",
    "            'date' : min(df['from_time']).date().strftime(\"%d-%m-%Y\"),\n",
    "            'time' : min(df['from_time']).strftime(\"%H:%M\"),\n",
    "            'duration' : str(duration*4), # duration in minutes * 4\n",
    "            'age' : '0',\n",
    "            'id' : f'{label}-Channel-{channel}',\n",
    "            'sex' : 'N'\n",
    "        }\n",
    "        \n",
    "        df_hrv = df[df.channel==channel]\n",
    "        \n",
    "        df_hrv = nni_to_hr_means(df_hrv)\n",
    "        \n",
    "        # remove duplicate\n",
    "        df_hrv = df_hrv.drop_duplicates(subset='from_time', keep='first')\n",
    "\n",
    "        # sort by from_time\n",
    "        df_hrv = df_hrv.sort_values(by='from_time')\n",
    "\n",
    "        records_per_day  = int(60 * 24 / duration)\n",
    "\n",
    "        start_date = datetime.combine(min(df_hrv.from_time).date(), datetime.min.time())\n",
    "        finish_date = datetime.combine(max(df_hrv.from_time).date(), datetime.min.time())\n",
    "        total_days = (finish_date - start_date).days + 1\n",
    "\n",
    "        data_log[channel] = {}\n",
    "\n",
    "        df_hr_filter = pd.DataFrame(columns=df_hrv.columns)\n",
    "        for day_num in range(total_days):\n",
    "            current_date = start_date + timedelta(days=day_num)\n",
    "            prev_date = current_date - timedelta(days=1)\n",
    "            next_date = current_date + timedelta(days=1)\n",
    "            df_records = df_hrv[df_hrv.from_time.gt(current_date) & df_hrv.from_time.le(next_date)]\n",
    "            data_log[channel][current_date] = df_records.shape[0]\n",
    "            if current_date == start_date:\n",
    "                pass\n",
    "            elif current_date == finish_date:\n",
    "                pass\n",
    "            else: # need to check\n",
    "                if df_records.shape[0] < records_per_day:\n",
    "                    data_add = [list(df_hrv.columns)]\n",
    "                    for i in range(records_per_day):\n",
    "                        check_0 = current_date + timedelta(minutes=duration*i)\n",
    "                        check_1 =  current_date + timedelta(minutes=duration*(i+1))\n",
    "                        p_check_0 = prev_date + timedelta(minutes=duration*i)\n",
    "                        p_check_1 =  prev_date + timedelta(minutes=duration*(i+1))\n",
    "                        n_check_0 = next_date + timedelta(minutes=duration*i)\n",
    "                        n_check_1 =  next_date + timedelta(minutes=duration*(i+1))\n",
    "                        available = df_records[df_records.from_time.gt(check_0) & df_records.from_time.le(check_1)]\n",
    "                        if len(available) == 0:\n",
    "                            # get previous day\n",
    "                            p_available = df_hrv[df_hrv.from_time.gt(p_check_0) & df_hrv.from_time.le(p_check_1)]\n",
    "                            # get next day\n",
    "                            n_available = df_hrv[df_hrv.from_time.gt(n_check_0) & df_hrv.from_time.le(n_check_1)]\n",
    "                            # now compare\n",
    "                            if len(p_available)+len(n_available) > 1:\n",
    "                                data_add += [[0, 0, (p_available.activity.iloc[0]+n_available.activity.iloc[0])/2,0, check_0, check_1, channel, (p_available.hr_means.iloc[0]+n_available.hr_means.iloc[0])/2]]\n",
    "                            elif len(p_available) > 0:\n",
    "                                added = [val for val in p_available.iloc[0]]\n",
    "                                added[4] = check_0\n",
    "                                added[5] = check_1\n",
    "                                data_add += [added]\n",
    "                            elif len(n_available) > 0:\n",
    "                                added = [val for val in n_available.iloc[0]]\n",
    "                                added[4] = check_0\n",
    "                                added[5] = check_1\n",
    "                                data_add += [added]\n",
    "                            else:\n",
    "                                data_add += [[0, 0, 0, 0, check_0, check_1, channel, 0]]\n",
    "                    if len(data_add)>1:\n",
    "                        #define second DataFrame\n",
    "                        data_add = {data[0]:data[1:]for data in list(zip(*data_add))}\n",
    "                        df_add = pd.DataFrame(data_add)\n",
    "                        #add new row to end of DataFrame\n",
    "                        df_records = pd.concat([df_records, df_add], ignore_index=True)\n",
    "\n",
    "                if df_records.shape[0] > records_per_day:\n",
    "                    df_records = df_records[:records_per_day]\n",
    "\n",
    "            df_hr_filter = pd.concat([df_hr_filter, df_records], ignore_index=True)\n",
    "        \n",
    "#         # interpolate empty data\n",
    "#         df_hr_filter['hr_means'] = df_hr_filter['hr_means'].replace(0.0, float('nan'))\n",
    "#         df_hr_filter = df_hr_filter.interpolate(method='nearest').bfill()\n",
    "        \n",
    "        df_hr_filter = df_hr_filter.sort_values('from_time')\n",
    "        \n",
    "        convert_to_awd(df_hr_filter, 'hr_means', f'hr_means_channel_{channel}_{csv_file.split(\".\")[0]}.awd', data_meta)\n",
    "        convert_to_awd(df_hr_filter, 'activity', f'activity_channel_{channel}_{csv_file.split(\".\")[0]}.awd', data_meta)\n",
    "        \n",
    "    return data_log\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47bfb87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zz/mk7_vrcn3r3gsbwr585w4blxzyk8xb/T/ipykernel_23176/1059794282.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['hr_means'] = df['nni'].apply(lambda x: __to_hr_mean(x))\n"
     ]
    }
   ],
   "source": [
    "pilot_1 = generate_awd_from_calculated_nni_df('actogram_2_10min.csv', [5, 8], 5, 'Mouse-Pilot2')\n",
    "pilot_2 = generate_awd_from_calculated_nni_df('actogram_1_10min.csv', [2], 5, 'Mouse-Pilot1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "24d0679c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zz/mk7_vrcn3r3gsbwr585w4blxzyk8xb/T/ipykernel_22480/3208912026.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['hr_means'] = df['nni'].apply(lambda x: __to_hr_mean(x))\n",
      "/var/folders/zz/mk7_vrcn3r3gsbwr585w4blxzyk8xb/T/ipykernel_22480/3208912026.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['hr_means'] = df['nni'].apply(lambda x: __to_hr_mean(x))\n"
     ]
    }
   ],
   "source": [
    "generate_awd_from_calculated_nni_df('actogram_2_5min.csv', [5, 8], 5, 'Mouse-Pilot2')\n",
    "generate_awd_from_calculated_nni_df('actogram_1_5min.csv', [2], 5, 'Mouse-Pilot1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b343f692",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-29 169\n",
      "2023-05-26 288\n",
      "2023-06-15 288\n",
      "2023-03-25 288\n",
      "2023-04-02 288\n",
      "2023-07-05 287\n",
      "2023-07-11 288\n",
      "2023-03-30 288\n",
      "2023-04-03 288\n",
      "2023-07-01 288\n",
      "2023-03-31 288\n",
      "2023-05-24 288\n",
      "2023-07-15 288\n",
      "2023-07-09 288\n",
      "2023-04-16 288\n",
      "2023-05-04 288\n",
      "2023-05-27 288\n",
      "2023-07-06 288\n",
      "2023-05-16 288\n",
      "2023-03-22 288\n",
      "2023-04-14 288\n",
      "2023-04-25 288\n",
      "2023-05-31 288\n",
      "2023-03-21 288\n",
      "2023-03-26 288\n",
      "2023-04-23 288\n",
      "2023-05-05 288\n",
      "2023-06-11 288\n",
      "2023-07-02 288\n",
      "2023-06-07 287\n",
      "2023-03-17 288\n",
      "2023-06-03 288\n",
      "2023-06-26 288\n",
      "2023-05-15 288\n",
      "2023-06-20 288\n",
      "2023-05-22 287\n",
      "2023-04-04 288\n",
      "2023-03-20 288\n",
      "2023-06-04 288\n",
      "2023-06-17 288\n",
      "2023-07-04 288\n",
      "2023-05-20 288\n",
      "2023-06-05 288\n",
      "2023-05-14 288\n",
      "2023-04-08 288\n",
      "2023-05-17 288\n",
      "2023-06-21 288\n",
      "2023-04-19 287\n",
      "2023-04-30 288\n",
      "2023-05-13 54\n",
      "2023-06-28 288\n",
      "2023-05-12 109\n",
      "2023-04-15 288\n",
      "2023-07-12 288\n",
      "2023-06-14 288\n",
      "2023-03-16 288\n",
      "2023-06-30 288\n",
      "2023-07-16 288\n",
      "2023-03-24 288\n",
      "2023-03-27 288\n",
      "2023-05-30 288\n",
      "2023-06-13 288\n",
      "2023-06-19 288\n",
      "2023-06-27 288\n",
      "2023-06-23 288\n",
      "2023-04-09 288\n",
      "2023-06-10 288\n",
      "2023-05-03 288\n",
      "2023-05-25 288\n",
      "2023-06-12 288\n",
      "2023-03-18 288\n",
      "2023-07-17 288\n",
      "2023-05-01 288\n",
      "2023-07-19 288\n",
      "2023-03-28 288\n",
      "2023-03-29 287\n",
      "2023-05-08 288\n",
      "2023-05-28 288\n",
      "2023-04-01 288\n",
      "2023-05-06 288\n",
      "2023-05-29 288\n",
      "2023-06-08 288\n",
      "2023-07-20 134\n",
      "2023-04-07 288\n",
      "2023-06-24 287\n",
      "2023-04-24 288\n",
      "2023-04-28 184\n",
      "2023-03-23 288\n",
      "2023-07-18 288\n",
      "2023-06-02 288\n",
      "2023-05-11 288\n",
      "2023-04-13 288\n",
      "2023-06-09 288\n",
      "2023-07-08 288\n",
      "2023-05-07 288\n",
      "2023-04-27 377\n",
      "2023-07-14 288\n",
      "2023-05-18 341\n",
      "2023-05-21 288\n",
      "2023-04-17 288\n",
      "2023-07-13 288\n",
      "2023-05-09 288\n",
      "2023-07-03 288\n",
      "2023-04-05 288\n",
      "2023-04-12 288\n",
      "2023-06-22 288\n",
      "2023-04-22 288\n",
      "2023-05-19 288\n",
      "2023-04-21 288\n",
      "2023-03-15 193\n",
      "2023-06-06 288\n",
      "2023-03-19 288\n",
      "2023-06-18 288\n",
      "2023-05-10 288\n",
      "2023-05-02 288\n",
      "2023-04-18 288\n",
      "2023-04-10 288\n",
      "2023-06-25 288\n",
      "2023-07-10 288\n",
      "2023-06-01 288\n",
      "2023-04-06 288\n",
      "2023-06-16 288\n",
      "2023-04-11 288\n",
      "2023-06-29 288\n",
      "2023-05-23 288\n",
      "2023-07-07 288\n",
      "2023-04-20 288\n",
      "2023-04-26 288\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for dt in set([s[0] for s in d.from_time.str.split(' ')]):\n",
    "    print(dt, len(d[(d['from_time'].str.contains(dt)) & (d['channel']==5)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "5c3eb892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_missing(csv_file, duration):\n",
    "    log_data = {'channel':[], 'date':[], 'total data':[], 'status data':[], 'missing':[]}\n",
    "    records_per_day  = int(60 * 24 / duration)\n",
    "    df = load_csv_file(csv_file)\n",
    "    channels = set(df['channel'])\n",
    "    \n",
    "    for channel in channels:\n",
    "        dfr = df[df.channel==channel].reset_index(drop=True)\n",
    "\n",
    "        start_date = datetime.combine(min(dfr.from_time).date(), datetime.min.time())\n",
    "        finish_date = datetime.combine(max(dfr.from_time).date(), datetime.min.time())\n",
    "        total_days = (finish_date - start_date).days + 1\n",
    "\n",
    "        for day_num in range(total_days):\n",
    "            current_date = start_date + timedelta(days=day_num)\n",
    "            next_date = current_date + timedelta(days=1)\n",
    "            df_records = dfr[dfr.from_time.gt(current_date) & dfr.from_time.le(next_date)].sort_values(by='from_time').reset_index(drop=True)\n",
    "            log_data['channel'] += [channel]\n",
    "            log_data['date'] += [current_date.strftime('%d-%m-%Y')]\n",
    "            log_data['total data'] += [df_records.shape[0]]\n",
    "            \n",
    "            if current_date in [start_date, finish_date]:\n",
    "                log_data['status data'] += ['begining/ending date']\n",
    "                log_data['missing'] += ['']\n",
    "            else: # need to check\n",
    "                if df_records.shape[0] > records_per_day:\n",
    "                    log_data['status data'] += ['containing duplicate/s']\n",
    "                    log_data['missing'] += ['']\n",
    "                elif df_records.shape[0] < records_per_day:\n",
    "                    missing_loc = []\n",
    "                    if df_records.shape[0] >= records_per_day-5:\n",
    "                        log_data['status data'] += ['missing 1-5 records']\n",
    "                        log_data['missing'] += ['']\n",
    "                        continue\n",
    "\n",
    "                    if df_records.shape[0] <= 1:\n",
    "                        log_data['status data'] += ['missing all/mostly']\n",
    "                        log_data['missing'] += ['']\n",
    "                        continue\n",
    "\n",
    "                    if (df_records.iloc[0]['from_time']-datetime.fromisoformat(current_date.isoformat())).total_seconds()/60 > duration:\n",
    "                        t1 = current_date.strftime('%d-%m-%Y %H:%M:%S')\n",
    "                        t2 = df_records.iloc[0]['from_time'].strftime('%d-%m-%Y %H:%M:%S')\n",
    "                        missing_loc += [f\"{t1} to {t2}\"]\n",
    "                    \n",
    "                    for i in df_records.index:\n",
    "                        if i == 0: continue\n",
    "                        if (df_records.iloc[i]['from_time']-df_records.iloc[i-1]['from_time']).total_seconds()/60 > duration:\n",
    "                            t1 = df_records.iloc[i-1]['from_time'].strftime('%d-%m-%Y %H:%M:%S')\n",
    "                            t2 = df_records.iloc[i]['from_time'].strftime('%d-%m-%Y %H:%M:%S')\n",
    "                            missing_loc += [f\"{t1} to {t2}\"]\n",
    "                    \n",
    "                    if (datetime.fromisoformat(next_date.isoformat()) - df_records.iloc[0]['from_time']).total_seconds()/60 > duration:\n",
    "                        t1 = df_records.iloc[0]['from_time'].strftime('%d-%m-%Y %H:%M:%S')\n",
    "                        t2 = next_date.strftime('%d-%m-%Y %H:%M:%S')\n",
    "                        missing_loc += [f\"{t1} to {t2}\"]\n",
    "                    \n",
    "                    log_data['status data'] += ['missing']\n",
    "                    log_data['missing'] += ['\\n'.join(missing_loc)]\n",
    "                else:\n",
    "                    log_data['status data'] += ['complete']\n",
    "                    log_data['missing'] += ['']\n",
    "        \n",
    "    return pd.DataFrame(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "987ecf47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_report1 = identify_missing('actogram_1_10min.csv', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "1203386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report2 = identify_missing('actogram_2_10min.csv', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "890b40e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_report1[(df_report1.channel==2) & (~(df_report1['status data']=='complete'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "1b77d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_report2[(df_report2.channel.isin([5,8])) & (~(df_report2['status data']=='complete'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "91f5e123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>date</th>\n",
       "      <th>total data</th>\n",
       "      <th>status data</th>\n",
       "      <th>missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>31-10-2022</td>\n",
       "      <td>162</td>\n",
       "      <td>begining/ending date</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>01-11-2022</td>\n",
       "      <td>126</td>\n",
       "      <td>missing</td>\n",
       "      <td>01-11-2022 00:01:47 to 02-11-2022 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>02-11-2022</td>\n",
       "      <td>0</td>\n",
       "      <td>missing all/mostly</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>03-11-2022</td>\n",
       "      <td>162</td>\n",
       "      <td>missing</td>\n",
       "      <td>03-11-2022 00:00:00 to 03-11-2022 10:32:12\\n03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>22-11-2022</td>\n",
       "      <td>287</td>\n",
       "      <td>missing 1-5 records</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>28-12-2022</td>\n",
       "      <td>287</td>\n",
       "      <td>missing 1-5 records</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>01-02-2023</td>\n",
       "      <td>287</td>\n",
       "      <td>missing 1-5 records</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>20-02-2023</td>\n",
       "      <td>273</td>\n",
       "      <td>begining/ending date</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>15-03-2023</td>\n",
       "      <td>193</td>\n",
       "      <td>begining/ending date</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>29-03-2023</td>\n",
       "      <td>287</td>\n",
       "      <td>missing 1-5 records</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>19-04-2023</td>\n",
       "      <td>287</td>\n",
       "      <td>missing 1-5 records</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>26-04-2023</td>\n",
       "      <td>286</td>\n",
       "      <td>missing 1-5 records</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>27-04-2023</td>\n",
       "      <td>377</td>\n",
       "      <td>containing duplicate/s</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>28-04-2023</td>\n",
       "      <td>184</td>\n",
       "      <td>missing</td>\n",
       "      <td>28-04-2023 00:00:00 to 28-04-2023 08:07:21\\n28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>29-04-2023</td>\n",
       "      <td>169</td>\n",
       "      <td>missing</td>\n",
       "      <td>29-04-2023 11:07:47 to 29-04-2023 21:06:35\\n29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>12-05-2023</td>\n",
       "      <td>109</td>\n",
       "      <td>missing</td>\n",
       "      <td>12-05-2023 00:04:42 to 13-05-2023 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>13-05-2023</td>\n",
       "      <td>54</td>\n",
       "      <td>missing</td>\n",
       "      <td>13-05-2023 00:00:00 to 13-05-2023 19:33:06\\n13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>18-05-2023</td>\n",
       "      <td>341</td>\n",
       "      <td>containing duplicate/s</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>22-05-2023</td>\n",
       "      <td>287</td>\n",
       "      <td>missing 1-5 records</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>07-06-2023</td>\n",
       "      <td>287</td>\n",
       "      <td>missing 1-5 records</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>24-06-2023</td>\n",
       "      <td>287</td>\n",
       "      <td>missing 1-5 records</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>05-07-2023</td>\n",
       "      <td>287</td>\n",
       "      <td>missing 1-5 records</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8</td>\n",
       "      <td>20-07-2023</td>\n",
       "      <td>134</td>\n",
       "      <td>begining/ending date</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>15-03-2023</td>\n",
       "      <td>193</td>\n",
       "      <td>begining/ending date</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>29-03-2023</td>\n",
       "      <td>287</td>\n",
       "      <td>missing 1-5 records</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>19-04-2023</td>\n",
       "      <td>287</td>\n",
       "      <td>missing 1-5 records</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>27-04-2023</td>\n",
       "      <td>377</td>\n",
       "      <td>containing duplicate/s</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>28-04-2023</td>\n",
       "      <td>184</td>\n",
       "      <td>missing</td>\n",
       "      <td>28-04-2023 00:00:00 to 28-04-2023 08:07:21\\n28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>29-04-2023</td>\n",
       "      <td>169</td>\n",
       "      <td>missing</td>\n",
       "      <td>29-04-2023 11:07:47 to 29-04-2023 21:06:35\\n29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>12-05-2023</td>\n",
       "      <td>109</td>\n",
       "      <td>missing</td>\n",
       "      <td>12-05-2023 00:04:42 to 13-05-2023 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>13-05-2023</td>\n",
       "      <td>54</td>\n",
       "      <td>missing</td>\n",
       "      <td>13-05-2023 00:00:00 to 13-05-2023 19:33:06\\n13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5</td>\n",
       "      <td>18-05-2023</td>\n",
       "      <td>341</td>\n",
       "      <td>containing duplicate/s</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>22-05-2023</td>\n",
       "      <td>287</td>\n",
       "      <td>missing 1-5 records</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5</td>\n",
       "      <td>07-06-2023</td>\n",
       "      <td>287</td>\n",
       "      <td>missing 1-5 records</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5</td>\n",
       "      <td>24-06-2023</td>\n",
       "      <td>287</td>\n",
       "      <td>missing 1-5 records</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5</td>\n",
       "      <td>05-07-2023</td>\n",
       "      <td>287</td>\n",
       "      <td>missing 1-5 records</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5</td>\n",
       "      <td>20-07-2023</td>\n",
       "      <td>134</td>\n",
       "      <td>begining/ending date</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    channel        date  total data             status data  \\\n",
       "0         2  31-10-2022         162    begining/ending date   \n",
       "1         2  01-11-2022         126                 missing   \n",
       "2         2  02-11-2022           0      missing all/mostly   \n",
       "3         2  03-11-2022         162                 missing   \n",
       "4         2  22-11-2022         287     missing 1-5 records   \n",
       "5         2  28-12-2022         287     missing 1-5 records   \n",
       "6         2  01-02-2023         287     missing 1-5 records   \n",
       "7         2  20-02-2023         273    begining/ending date   \n",
       "8         8  15-03-2023         193    begining/ending date   \n",
       "9         8  29-03-2023         287     missing 1-5 records   \n",
       "10        8  19-04-2023         287     missing 1-5 records   \n",
       "11        8  26-04-2023         286     missing 1-5 records   \n",
       "12        8  27-04-2023         377  containing duplicate/s   \n",
       "13        8  28-04-2023         184                 missing   \n",
       "14        8  29-04-2023         169                 missing   \n",
       "15        8  12-05-2023         109                 missing   \n",
       "16        8  13-05-2023          54                 missing   \n",
       "17        8  18-05-2023         341  containing duplicate/s   \n",
       "18        8  22-05-2023         287     missing 1-5 records   \n",
       "19        8  07-06-2023         287     missing 1-5 records   \n",
       "20        8  24-06-2023         287     missing 1-5 records   \n",
       "21        8  05-07-2023         287     missing 1-5 records   \n",
       "22        8  20-07-2023         134    begining/ending date   \n",
       "23        5  15-03-2023         193    begining/ending date   \n",
       "24        5  29-03-2023         287     missing 1-5 records   \n",
       "25        5  19-04-2023         287     missing 1-5 records   \n",
       "26        5  27-04-2023         377  containing duplicate/s   \n",
       "27        5  28-04-2023         184                 missing   \n",
       "28        5  29-04-2023         169                 missing   \n",
       "29        5  12-05-2023         109                 missing   \n",
       "30        5  13-05-2023          54                 missing   \n",
       "31        5  18-05-2023         341  containing duplicate/s   \n",
       "32        5  22-05-2023         287     missing 1-5 records   \n",
       "33        5  07-06-2023         287     missing 1-5 records   \n",
       "34        5  24-06-2023         287     missing 1-5 records   \n",
       "35        5  05-07-2023         287     missing 1-5 records   \n",
       "36        5  20-07-2023         134    begining/ending date   \n",
       "\n",
       "                                              missing  \n",
       "0                                                      \n",
       "1          01-11-2022 00:01:47 to 02-11-2022 00:00:00  \n",
       "2                                                      \n",
       "3   03-11-2022 00:00:00 to 03-11-2022 10:32:12\\n03...  \n",
       "4                                                      \n",
       "5                                                      \n",
       "6                                                      \n",
       "7                                                      \n",
       "8                                                      \n",
       "9                                                      \n",
       "10                                                     \n",
       "11                                                     \n",
       "12                                                     \n",
       "13  28-04-2023 00:00:00 to 28-04-2023 08:07:21\\n28...  \n",
       "14  29-04-2023 11:07:47 to 29-04-2023 21:06:35\\n29...  \n",
       "15         12-05-2023 00:04:42 to 13-05-2023 00:00:00  \n",
       "16  13-05-2023 00:00:00 to 13-05-2023 19:33:06\\n13...  \n",
       "17                                                     \n",
       "18                                                     \n",
       "19                                                     \n",
       "20                                                     \n",
       "21                                                     \n",
       "22                                                     \n",
       "23                                                     \n",
       "24                                                     \n",
       "25                                                     \n",
       "26                                                     \n",
       "27  28-04-2023 00:00:00 to 28-04-2023 08:07:21\\n28...  \n",
       "28  29-04-2023 11:07:47 to 29-04-2023 21:06:35\\n29...  \n",
       "29         12-05-2023 00:04:42 to 13-05-2023 00:00:00  \n",
       "30  13-05-2023 00:00:00 to 13-05-2023 19:33:06\\n13...  \n",
       "31                                                     \n",
       "32                                                     \n",
       "33                                                     \n",
       "34                                                     \n",
       "35                                                     \n",
       "36                                                     "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "5eba1bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel                 8\n",
       "date           09-05-2023\n",
       "total data            288\n",
       "status data      complete\n",
       "missing                  \n",
       "Name: 55, dtype: object"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report2.iloc[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab204485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
